# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per a2, 
# in this case called 'a2'

# 为当前的agent设置各个组件的名称
a2.sources = r1
a2.channels = c1
a2.sinks = k1


# 定义source组件的类型及参数
a2.sources.r1.type = exec
a2.sources.r1.command = tail -f /var/log/httpd/access_log
a2.sources.r1.shell = /bin/bash -c


#定义channels组件的类型及参数
#使用内存进行缓冲数据
a2.channels.c1.type = memory
#在channel中缓存events的最大数量，默认值是100
a2.channels.c1.capacity = 100
#source推送到channel 或者 sink从channel拉取 event 的最大数量
a2.channels.c1.transactionCapacity = 100


#定义sink的类型及参数
a2.sinks.k1.type = hdfs
a2.sinks.k1.hdfs.path = hdfs://bd-server1:8020/flume/events/%Y%m%d/%H
#文件的前缀
a2.sinks.k1.hdfs.filePrefix = events-
#文件的后缀
a2.sinks.k1.hdfs.fileSuffix = .log

#控制生成时间目录的参数，开启控制，并且每小时滚动一次目录
a2.sinks.k1.hdfs.round = true
a2.sinks.k1.hdfs.roundValue = 1
a2.sinks.k1.hdfs.roundUnit = hour

#使用本地时间戳，注意：如果目录是二级时间分区目录，这个参数一定要配置
a2.sinks.k1.hdfs.useLocalTimeStamp = true

#控制文件滚动规则
#每30秒滚动生成一个新文件
a2.sinks.k1.hdfs.rollInterval = 30
#根据文件的大小来滚动生成一个新文件，推荐和block size一样,128M换算成字节
a2.sinks.k1.hdfs.rollSize = 2048
#根据event的数量控制文件的生成，一般设置为0，忽略这个参数
a2.sinks.k1.hdfs.rollCount = 0

#手动将值设置为1，让flume感应不到hdfs文件块的复制，其实副本数还是3
a2.sinks.k1.hdfs.minBlockReplicas = 1

#设置生成的文件类型
a2.sinks.k1.hdfs.fileType = DataStream
a2.sinks.k1.hdfs.writeFormat = Text


#将channel连接对应的source和sink
a2.sources.r1.channels = c1
a2.sinks.k1.channel = c1
























